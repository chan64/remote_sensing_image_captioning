{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sample-lstm2 (1).ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"scrolled":true,"id":"8R_RnYiB_GWI","colab_type":"code","colab":{}},"cell_type":"code","source":["from numpy import array\n","from pickle import load,dump\n","import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.utils import plot_model\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Embedding\n","from keras.layers import Dropout\n","from keras.layers import Bidirectional\n","from keras.layers import *\n","from keras.layers.merge import add\n","from keras.callbacks import ModelCheckpoint\n","import pydot\n","from numpy import argmax\n","from nltk.translate.bleu_score import corpus_bleu"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0uSGxxjsRK8p","colab_type":"code","outputId":"fe28f049-3353-4cbc-e5c1-2e6e34608aba","executionInfo":{"status":"ok","timestamp":1556007306289,"user_tz":-330,"elapsed":27896,"user":{"displayName":"Chandeesh Kumar","photoUrl":"https://lh4.googleusercontent.com/--MT8mrFpMqE/AAAAAAAAAAI/AAAAAAAAP2E/43g8ggDCRdk/s64/photo.jpg","userId":"17069823236948718831"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"scrolled":true,"id":"FzrY_1kK_GWh","colab_type":"code","outputId":"b847daad-e9ec-4a64-9d08-57bc60a08de3","executionInfo":{"status":"ok","timestamp":1556008462415,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Chandeesh Kumar","photoUrl":"https://lh4.googleusercontent.com/--MT8mrFpMqE/AAAAAAAAAAI/AAAAAAAAP2E/43g8ggDCRdk/s64/photo.jpg","userId":"17069823236948718831"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n"," \n","# load a pre-defined list of photo identifiers\n","def load_set(filename):\n","\tdoc = load_doc(filename)\n","\tdataset = list()\n","\t# process line by line\n","\tfor line in doc.split('\\n'):\n","\t\t# skip empty lines\n","\t\tif len(line) < 1:\n","\t\t\tcontinue\n","\t\t# get the image identifier\n","\t\tidentifier = line.split(' ')[0]\n","\t\tdataset.append(identifier)\n","\treturn set(dataset)\n"," \n","# load clean descriptions into memory\n","def load_clean_descriptions(filename, dataset):\n","\t# load document\n","\tdoc = load_doc(filename)\n","\tdescriptions = dict()\n","\tfor line in doc.split('\\n'):\n","\t\t# split line by white space\n","\t\ttokens = line.split()\n","\t\t# split id from description\n","\t\timage_id, image_desc = tokens[0], tokens[1:]\n","\t\t# skip images not in the set\n","\t\tif image_id in dataset:\n","\t\t\t# create list\n","\t\t\tif image_id not in descriptions:\n","\t\t\t\tdescriptions[image_id] = list()\n","\t\t\t# wrap description in tokens\n","\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n","\t\t\t# store\n","\t\t\tdescriptions[image_id].append(desc)\n","\treturn descriptions\n"," \n","# load photo features\n","def load_photo_features(filename, dataset):\n","    # load all features\n","    all_features = load(open(filename, 'rb'))\n","    #print(all_features)\n","    # filter features\n","    features = {k: all_features[k] for k in dataset}\n","    return features\n"," \n","# covert a dictionary of clean descriptions to a list of descriptions\n","def to_lines(descriptions):\n","\tall_desc = list()\n","\tfor key in descriptions.keys():\n","\t\t[all_desc.append(d) for d in descriptions[key]]\n","\treturn all_desc\n"," \n","# fit a tokenizer given caption descriptions\n","def create_tokenizer(descriptions):\n","\tlines = to_lines(descriptions)\n","\ttokenizer = Tokenizer()\n","\ttokenizer.fit_on_texts(lines)\n","\treturn tokenizer\n"," \n","# calculate the length of the description with the most words\n","def max_length(descriptions):\n","\tlines = to_lines(descriptions)\n","\treturn max(len(d.split()) for d in lines)\n"," \n","# create sequences of images, input sequences and output words for an image\n","def create_sequences(tokenizer, max_length, desc_list, photo):\n","\tX1, X2, y = list(), list(), list()\n","\t# walk through each description for the image\n","\tfor desc in desc_list:\n","\t\t# encode the sequence\n","\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n","\t\t# split one sequence into multiple X,y pairs\n","\t\tfor i in range(1, len(seq)):\n","\t\t\t# split into input and output pair\n","\t\t\tin_seq, out_seq = seq[:i], seq[i]\n","\t\t\t# pad input sequence\n","\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","\t\t\t# encode output sequence\n","\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","\t\t\t# store\n","\t\t\tX1.append(photo)\n","\t\t\tX2.append(in_seq)\n","\t\t\ty.append(out_seq)\n","\treturn array(X1), array(X2), array(y)\n"," \n","#data generator, intended to be used in a call to model.fit_generator()\n","def data_generator(descriptions, photos, tokenizer, max_length):\n","\t# loop for ever over images\n","\twhile 1:\n","\t\tfor key, desc_list in descriptions.items():\n","\t\t\t# retrieve the photo feature\n","\t\t\tphoto = photos[key][0]\n","\t\t\tin_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo)\n","\t\t\tyield [[in_img, in_seq], out_word]\n","\n","# load training dataset (6K)\n","filename = 'drive/My Drive/Final Year Project/Descriptions/trainuc.txt'\n","train = load_set(filename)\n","#print(sorted(train))\n","print('Dataset: %d' % len(train))\n","# descriptions\n","train_descriptions = load_clean_descriptions('drive/My Drive/Final Year Project/Descriptions/trainuc.txt', train)\n","print('Descriptions: train=%d' % len(train_descriptions))\n","# photo features\n","#print(train)\n","#all_features = load(open('features_inceptionv3_uc.pkl', 'rb'))\n","#print(all_features)\n","train_features = load_photo_features('drive/My Drive/Final Year Project/Features/features_uc_resnet152_updated.pkl', train)\n","print('Photos: train=%d' % len(train_features))\n","# prepare tokenizer\n","tokenizer = create_tokenizer(train_descriptions)\n","#dump(tokenizer,open('tokenizer_resnet152.pkl','wb'))\n","vocab_size = len(tokenizer.word_index) + 1\n","print('Vocabulary Size: %d' % vocab_size)\n","## determine the maximum sequence length\n","max_length = max_length(train_descriptions)\n","print('Description Length: %d' % max_length)\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset: 1260\n","Descriptions: train=1260\n","Photos: train=1260\n","Vocabulary Size: 293\n","Description Length: 24\n"],"name":"stdout"}]},{"metadata":{"id":"3gEstZk0_GXb","colab_type":"code","colab":{}},"cell_type":"code","source":["# map an integer to a word\n","def word_for_id(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None\n"," \n","# generate a description for an image\n","def generate_desc(model, tokenizer, photo, max_length):\n","\t# seed the generation process\n","\tin_text = 'startseq'\n","\t# iterate over the whole length of the sequence\n","\tfor i in range(max_length):\n","\t\t# integer encode input sequence\n","\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n","\t\t# pad input\n","\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n","\t\t# predict next word\n","\t\tyhat = model.predict([photo,sequence], verbose=0)\n","\t\t# convert probability to integer\n","\t\tyhat = argmax(yhat)\n","\t\t# map integer to word\n","\t\tword = word_for_id(yhat, tokenizer)\n","\t\t# stop if we cannot map the word\n","\t\tif word is None:\n","\t\t\tbreak\n","\t\t# append as input for generating the next word\n","\t\tin_text += ' ' + word\n","\t\t# stop if we predict the end of the sequence\n","\t\tif word == 'endseq':\n","\t\t\tbreak\n","\treturn in_text\n"," \n","# evaluate the skill of the model\n","def evaluate_model(model, descriptions, photos, tokenizer, max_length,filename):\n","    actual, predicted = list(), list()\n","    # step over the whole set\n","    lines = list()\n","    for key, desc_list in descriptions.items():\n","        yhat = generate_desc(model, tokenizer, photos[key], max_length)\n","        ex=yhat\n","        a=yhat.split('startseq')\n","        b=a[1].split('endseq')\n","        lines.append('beam_size_1'+'\\t'+key + '\\t' + b[0])\n","        references = [d.split() for d in desc_list]\n","        actual.append(references)\n","        predicted.append(yhat.split())\n","        #\n","    data = '\\n'.join(lines)\n","    file = open(filename, 'w')\n","    file.write(data)\n","    file.close()\n","    bleu=np.zeros(4)\n","    # calculate BLEU score\n","    bleu[0]=corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n","    bleu[1]=corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n","    bleu[2]=corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n","    bleu[3]=corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n","    print('BLEU-1: %f' % bleu[0])\n","    print('BLEU-2: %f' % bleu[1])\n","    print('BLEU-3: %f' % bleu[2])\n","    print('BLEU-4: %f' % bleu[3])\n","    return bleu"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xuQauFFs_GX1","colab_type":"code","outputId":"33ff7fdb-b922-46c0-81e5-e875cffe20c4","executionInfo":{"status":"ok","timestamp":1556008492561,"user_tz":-330,"elapsed":1814,"user":{"displayName":"Chandeesh Kumar","photoUrl":"https://lh4.googleusercontent.com/--MT8mrFpMqE/AAAAAAAAAAI/AAAAAAAAP2E/43g8ggDCRdk/s64/photo.jpg","userId":"17069823236948718831"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["# load test set\n","filename = 'drive/My Drive/Final Year Project/Descriptions/testall.txt'\n","test = load_set(filename)\n","print('Dataset: %d' % len(test))\n","# descriptions\n","test_descriptions = load_clean_descriptions('drive/My Drive/Final Year Project/Descriptions/testall.txt', test)\n","print('Descriptions: test=%d' % len(test_descriptions))\n","# photo features\n","test_features = load_photo_features('drive/My Drive/Final Year Project/Features/features_resnet152_combined.pkl', test)\n","print('Photos: test=%d' % len(test_features))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset: 705\n","Descriptions: test=705\n","Photos: test=705\n"],"name":"stdout"}]},{"metadata":{"id":"dkm4U-jj_GYJ","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import backend as K\n","from keras.engine.topology import Layer\n","from keras import initializers, regularizers, constraints\n","\n","\n","class Attention(Layer):\n","    def __init__(self, step_dim=max_length,\n","                 W_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        super(Attention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        self.features_dim = input_shape[-1]\n","\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","        else:\n","            self.b = None\n","\n","        self.built = True\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return None\n","\n","    def call(self, x, mask=None):\n","        features_dim = self.features_dim\n","        step_dim = self.step_dim\n","\n","        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n","                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n","\n","        if self.bias:\n","            eij += self.b\n","\n","        eij = K.tanh(eij)\n","\n","        a = K.exp(eij)\n","\n","        if mask is not None:\n","            a *= K.cast(mask, K.floatx())\n","\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0],  self.features_dim\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q_F8cA6l_GYY","colab_type":"code","colab":{}},"cell_type":"code","source":["# load a word embedding\n","def load_embedding(tokenizer, vocab_size, max_length):\n","\t# load the tokenizer\n","\tembedding = load(open('UCMDataset1/Features/word2vec_embedding.pkl', 'rb'))\n","\tdimensions = 100\n","\ttrainable = False\n","\t# create a weight matrix for words in training docs\n","\tweights = np.zeros((vocab_size, dimensions))\n","\t# walk words in order of tokenizer vocab to ensure vectors are in the right index\n","\tfor word, i in tokenizer.word_index.items():\n","\t\tif word not in embedding:\n","\t\t\tcontinue\n","\t\tweights[i] = embedding[word]\n","\tlayer = Embedding(vocab_size, dimensions, weights=[weights], input_length=max_length, trainable=trainable, mask_zero=True)\n","\treturn layer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5FzSf8AC_GYp","colab_type":"code","colab":{}},"cell_type":"code","source":["loc = 'drive/My Drive/Final Year Project/Modeluc/'\n","# define the captioning model\n","def define_model(vocab_size, max_length):\n","    # feature extractor model\n","    inputs1 = Input(shape=(2048,))\n","    #fe1 = Dropout(0.5)(inputs1)\n","    fe2 = Dense(256, activation='relu')(inputs1)\n","    fe3 = RepeatVector(max_length)(fe2)\n","    # sequence model\n","    inputs2 = Input(shape=(max_length,))\n","    #se1 = load_embedding(tokenizer, vocab_size, max_length)(inputs2)\n","    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n","    #print(se1.shape)\n","    se2 = LSTM(256,return_sequences=True)(se1)\n","    #print(se2.shape)\n","    #x = Attention(max_length)(se2) \n","    #print(x.shape)\n","    se3 = TimeDistributed(Dense(256,activation='relu'))(se2)\n","    #print(se3.shape)\n","    # decoder model\n","    decoder1 = concatenate([fe3, se3])\n","    decoder2 = Bidirectional(LSTM(150,return_sequences=True))(decoder1)\n","    decoder3 = Attention(max_length)(decoder2)\n","    outputs = Dense(vocab_size, activation='softmax')(decoder3)\n","    # tie it together [image, seq] [word]\n","    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","    # compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","    # summarize model\n","    model.summary()\n","    plot_model(model, to_file=loc+'model.png', show_shapes=True)\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R9KYAjRI_GY6","colab_type":"code","outputId":"7cd07b1a-b5ac-4ca4-ba73-187cd9e3f96d","executionInfo":{"status":"ok","timestamp":1556008570321,"user_tz":-330,"elapsed":5990,"user":{"displayName":"Chandeesh Kumar","photoUrl":"https://lh4.googleusercontent.com/--MT8mrFpMqE/AAAAAAAAAAI/AAAAAAAAP2E/43g8ggDCRdk/s64/photo.jpg","userId":"17069823236948718831"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"cell_type":"code","source":["model = define_model(vocab_size, max_length)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            (None, 24)           0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, 2048)         0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 24, 256)      75008       input_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 256)          524544      input_3[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_3 (LSTM)                   (None, 24, 256)      525312      embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","repeat_vector_2 (RepeatVector)  (None, 24, 256)      0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","time_distributed_2 (TimeDistrib (None, 24, 256)      65792       lstm_3[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 24, 512)      0           repeat_vector_2[0][0]            \n","                                                                 time_distributed_2[0][0]         \n","__________________________________________________________________________________________________\n","bidirectional_2 (Bidirectional) (None, 24, 300)      795600      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","attention_2 (Attention)         (None, 300)          324         bidirectional_2[0][0]            \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 293)          88193       attention_2[0][0]                \n","==================================================================================================\n","Total params: 2,074,773\n","Trainable params: 2,074,773\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"EwKjqc6N_GZQ","colab_type":"code","outputId":"5399ec58-6668-49fc-90a8-93e8c106ef0b","executionInfo":{"status":"ok","timestamp":1556012138722,"user_tz":-330,"elapsed":3517113,"user":{"displayName":"Chandeesh Kumar","photoUrl":"https://lh4.googleusercontent.com/--MT8mrFpMqE/AAAAAAAAAAI/AAAAAAAAP2E/43g8ggDCRdk/s64/photo.jpg","userId":"17069823236948718831"}},"colab":{"base_uri":"https://localhost:8080/","height":1057}},"cell_type":"code","source":["## train the model, run epochs manually and save after each epoch\n","epochs = 20\n","steps = len(train_descriptions)\n","mylist = list()\n","df=pd.DataFrame(index=mylist, columns=['model_no','Bleu_1','Bleu_2','Bleu_3','Bleu_4'])\n","for i in range(1,epochs):\n","    print(i)\n","    # create the data generator\n","    generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n","    # fit for one epoch\n","    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n","    # save model\n","    model.save(loc+'model_' + str(i) + '.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/1\n","1260/1260 [==============================] - 192s 152ms/step - loss: 3.0008\n","2\n","Epoch 1/1\n","1260/1260 [==============================] - 186s 148ms/step - loss: 1.4319\n","3\n","Epoch 1/1\n","1260/1260 [==============================] - 184s 146ms/step - loss: 0.7636\n","4\n","Epoch 1/1\n","1260/1260 [==============================] - 185s 147ms/step - loss: 0.5542\n","5\n","Epoch 1/1\n","1260/1260 [==============================] - 184s 146ms/step - loss: 0.4650\n","6\n","Epoch 1/1\n","1260/1260 [==============================] - 182s 145ms/step - loss: 0.4128\n","7\n","Epoch 1/1\n","1260/1260 [==============================] - 184s 146ms/step - loss: 0.3710\n","8\n","Epoch 1/1\n","1260/1260 [==============================] - 182s 145ms/step - loss: 0.3377\n","9\n","Epoch 1/1\n","1260/1260 [==============================] - 183s 145ms/step - loss: 0.3086\n","10\n","Epoch 1/1\n","1260/1260 [==============================] - 183s 145ms/step - loss: 0.2911\n","11\n","Epoch 1/1\n","1260/1260 [==============================] - 185s 147ms/step - loss: 0.2778\n","12\n","Epoch 1/1\n","1260/1260 [==============================] - 186s 147ms/step - loss: 0.2612\n","13\n","Epoch 1/1\n","1260/1260 [==============================] - 183s 146ms/step - loss: 0.2531\n","14\n","Epoch 1/1\n","1260/1260 [==============================] - 184s 146ms/step - loss: 0.2485\n","15\n","Epoch 1/1\n","1260/1260 [==============================] - 185s 147ms/step - loss: 0.2429\n","16\n","Epoch 1/1\n","1260/1260 [==============================] - 184s 146ms/step - loss: 0.2295\n","17\n","Epoch 1/1\n","1260/1260 [==============================] - 186s 147ms/step - loss: 0.2238\n","18\n","Epoch 1/1\n","1260/1260 [==============================] - 185s 147ms/step - loss: 0.2197\n","19\n","Epoch 1/1\n","1260/1260 [==============================] - 185s 147ms/step - loss: 0.2190\n"],"name":"stdout"}]},{"metadata":{"id":"4sbjVUd__GZ_","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}